{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Util.utilities import *\n",
    "from Util.price_features import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "df_ohlcv = pd.read_csv('Analysis/data/full_5m_futures/XRPUSDT_futures_5m_202001_202404.csv', index_col=0)\n",
    "df_ohlcv['barID'] = df_ohlcv.reset_index().index.values\n",
    "df_ohlcv.set_index('Time', inplace=True)\n",
    "df_ohlcv.index = pd.to_datetime(df_ohlcv.index, unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Sampling\n",
    "lookback = 100\n",
    "feat = getBollinger(df_ohlcv.Close, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = getCrossingEvents_dynamicExit(feat, df_ohlcv, -2.75, 0, 'downward', 'upward', 0)\n",
    "ret = get_lrets(events, df_ohlcv, commission = 0.001, betSize = 1)\n",
    "Y = pd.DataFrame(index =ret.index)\n",
    "Y['ret'] = ret\n",
    "Y['bin'] = (ret>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Library\n",
    "# 13개\n",
    "def add_featureSetA (X, tEvent, df, scale, lookback):\n",
    "    print(f'Adding Feature Set A with lookback={lookback} and scale {scale}')\n",
    "    close_path = getPathMatrix(df.Close, tEvent, nbars = lookback, scale = scale)\n",
    "    lrets_path = np.log(close_path).diff(axis=1)\n",
    "    \n",
    "    X[f'sharpe1_{scale}'] = (lrets_path.sum(axis=1)/np.sqrt((lrets_path**2).sum(axis=1)))\n",
    "    X[f'sharpe2_{scale}'] = (lrets_path.sum(axis=1)/lrets_path.std(axis=1))\n",
    "    X[f'returns_{scale}'] = lrets_path.sum(axis=1)\n",
    "    X[f'std_{scale}'] = lrets_path.std(axis=1)\n",
    "    X[f'vol_{scale}'] = np.sqrt((lrets_path**2).sum(axis=1))\n",
    "\n",
    "    X[f'blgr_{scale}'] = getBollinger(df.Close, lookback*scale)[tEvent]\n",
    "    X[f'trend_{scale}'] = getTrend(tEvent, df.Close, lookback, scale = scale, use_log=True)\n",
    "    X[f'trendblgr_{scale}'] = getTrendBlgr(tEvent, df.Close, lookback, scale = scale, use_log=True)\n",
    "    X[f'willR_{scale}'] = williamsR(df.Close, lookback*scale, nFrac=10)[tEvent]\n",
    "\n",
    "    X[f'ar1_{scale}'] = getAR1(tEvent, df.Close, lookback, scale=scale, use_log=True)\n",
    "    X[f'adf_{scale}'] = getADF(tEvent, df.Close, lookback, scale=scale,  constant ='c', lags = int(lookback*0.1),)                      \n",
    "\n",
    "    X[f'macd_norm1_{scale}'] = getMACD_norm(df.Close, span_short = scale*lookback//4, span_long = scale*lookback//2, use_ewm = False)[tEvent]\n",
    "    X[f'macd_norm2_{scale}'] = getMACD_norm(df.Close, span_short = scale*lookback//2, span_long = scale*lookback, use_ewm = False)[tEvent]\n",
    "    return X\n",
    "\n",
    "# 총 30개\n",
    "def add_featureSetB(X, tEvent, df, scale, lookback):\n",
    "    print(f'Adding Feature Set B with lookback={lookback} and scale = {scale}')\n",
    "    import ta\n",
    "    lookback = lookback*scale\n",
    "    \n",
    "    # # Volume (2)\n",
    "    X[f'cmf_{scale}'] = ta.volume.ChaikinMoneyFlowIndicator(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], window=lookback).chaikin_money_flow().loc[tEvent]\n",
    "    X[f'mfi_{scale}'] = ta.volume.MFIIndicator(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], window=lookback).money_flow_index().loc[tEvent]\n",
    "\n",
    "    # Volatility Indicators (6)\n",
    "    X[f'bbw_{scale}'] = ta.volatility.BollingerBands(close=df['Close'], window=lookback).bollinger_wband().loc[tEvent]\n",
    "    X[f'bbp_{scale}'] = ta.volatility.BollingerBands(close=df['Close'], window=lookback).bollinger_pband().loc[tEvent]\n",
    "    X[f'kcw_{scale}'] = ta.volatility.KeltnerChannel(close=df['Close'], high=df['High'], low=df['Low'], window=lookback).keltner_channel_wband().loc[tEvent]\n",
    "    X[f'dcw_{scale}'] = ta.volatility.DonchianChannel(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).donchian_channel_wband().loc[tEvent]\n",
    "    X[f'dcp_{scale}'] = ta.volatility.DonchianChannel(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).donchian_channel_pband().loc[tEvent]\n",
    "    X[f'ui_{scale}'] = ta.volatility.UlcerIndex(close=df['Close'], window=lookback).ulcer_index().loc[tEvent]\n",
    "\n",
    "    # Trend Indicators (12)\n",
    "    X[f'vortex_ind_diff_{scale}'] = ta.trend.VortexIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).vortex_indicator_diff().loc[tEvent]\n",
    "    X[f'trix_{scale}'] = ta.trend.TRIXIndicator(close=df['Close'], window=lookback).trix().loc[tEvent]\n",
    "    X[f'kst_{scale}'] = ta.trend.KSTIndicator(close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3, window4=lookback*4).kst().loc[tEvent]\n",
    "    X[f'kst_sig_{scale}'] = ta.trend.KSTIndicator(close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3, window4=lookback*4).kst_sig().loc[tEvent]\n",
    "    X[f'kst_diff_{scale}'] = ta.trend.KSTIndicator(close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3, window4=lookback*4).kst_diff().loc[tEvent]\n",
    "    X[f'stc_{scale}'] = ta.trend.STCIndicator(close=df['Close'], window_slow=lookback, window_fast=lookback//2).stc().loc[tEvent]\n",
    "    X[f'adx_{scale}'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).adx().loc[tEvent]\n",
    "    X[f'adx_pos_{scale}'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).adx_pos().loc[tEvent]\n",
    "    X[f'adx_neg_{scale}'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).adx_neg().loc[tEvent]\n",
    "    X[f'aroon_up_{scale}'] = ta.trend.AroonIndicator(high=df['High'], low=df['Low'], window=lookback).aroon_up().loc[tEvent]\n",
    "    X[f'aroon_down_{scale}'] = ta.trend.AroonIndicator(high=df['High'], low=df['Low'], window=lookback).aroon_down().loc[tEvent]\n",
    "    X[f'aroon_ind_{scale}'] = ta.trend.AroonIndicator(high=df['High'], low=df['Low'], window=lookback).aroon_indicator().loc[tEvent]\n",
    "\n",
    "    # Momentum Indicators (10)\n",
    "    X[f'stoch_rsi_{scale}'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=lookback).stochrsi().loc[tEvent]\n",
    "    X[f'stoch_rsi_k_{scale}'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=lookback).stochrsi_k().loc[tEvent]\n",
    "    X[f'stoch_rsi_d_{scale}'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=lookback).stochrsi_d().loc[tEvent]\n",
    "    X[f'tsi_{scale}'] = ta.momentum.TSIIndicator(close=df['Close'], window_slow=lookback, window_fast=lookback//2).tsi().loc[tEvent]\n",
    "    X[f'uo_{scale}'] = ta.momentum.UltimateOscillator(high=df['High'], low=df['Low'], close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3).ultimate_oscillator().loc[tEvent]\n",
    "    X[f'stoch_{scale}'] = ta.momentum.StochasticOscillator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).stoch().loc[tEvent]\n",
    "    X[f'stoch_sig_{scale}'] = ta.momentum.StochasticOscillator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).stoch_signal().loc[tEvent]\n",
    "    X[f'wr_{scale}'] = ta.momentum.WilliamsRIndicator(high=df['High'], low=df['Low'], close=df['Close'], lbp=lookback).williams_r().loc[tEvent]\n",
    "    X[f'ppo_{scale}'] = ta.momentum.PercentagePriceOscillator(close=df['Close'], window_slow=lookback, window_fast=lookback//2, window_sign = lookback//3).ppo().loc[tEvent]\n",
    "    X[f'ppo_signal_{scale}'] = ta.momentum.PercentagePriceOscillator(close=df['Close'], window_slow=lookback, window_fast=lookback//2, window_sign = lookback//3).ppo_signal().loc[tEvent]\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Feature Set A with lookback=100 and scale 1\n",
      "Adding Feature Set B with lookback=100 and scale = 1\n",
      "Adding Feature Set A with lookback=100 and scale 4\n",
      "Adding Feature Set B with lookback=100 and scale = 4\n",
      "Adding Feature Set A with lookback=100 and scale 10\n",
      "Adding Feature Set B with lookback=100 and scale = 10\n",
      "Adding Feature Set A with lookback=100 and scale 40\n",
      "Adding Feature Set B with lookback=100 and scale = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'kst_{scale}'] = ta.trend.KSTIndicator(close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3, window4=lookback*4).kst().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'kst_sig_{scale}'] = ta.trend.KSTIndicator(close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3, window4=lookback*4).kst_sig().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'kst_diff_{scale}'] = ta.trend.KSTIndicator(close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3, window4=lookback*4).kst_diff().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'stc_{scale}'] = ta.trend.STCIndicator(close=df['Close'], window_slow=lookback, window_fast=lookback//2).stc().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'adx_{scale}'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).adx().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'adx_pos_{scale}'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).adx_pos().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'adx_neg_{scale}'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).adx_neg().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'aroon_up_{scale}'] = ta.trend.AroonIndicator(high=df['High'], low=df['Low'], window=lookback).aroon_up().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'aroon_down_{scale}'] = ta.trend.AroonIndicator(high=df['High'], low=df['Low'], window=lookback).aroon_down().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'aroon_ind_{scale}'] = ta.trend.AroonIndicator(high=df['High'], low=df['Low'], window=lookback).aroon_indicator().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'stoch_rsi_{scale}'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=lookback).stochrsi().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'stoch_rsi_k_{scale}'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=lookback).stochrsi_k().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'stoch_rsi_d_{scale}'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=lookback).stochrsi_d().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'tsi_{scale}'] = ta.momentum.TSIIndicator(close=df['Close'], window_slow=lookback, window_fast=lookback//2).tsi().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'uo_{scale}'] = ta.momentum.UltimateOscillator(high=df['High'], low=df['Low'], close=df['Close'], window1=lookback, window2=lookback*2, window3=lookback*3).ultimate_oscillator().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'stoch_{scale}'] = ta.momentum.StochasticOscillator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).stoch().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'stoch_sig_{scale}'] = ta.momentum.StochasticOscillator(high=df['High'], low=df['Low'], close=df['Close'], window=lookback).stoch_signal().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'wr_{scale}'] = ta.momentum.WilliamsRIndicator(high=df['High'], low=df['Low'], close=df['Close'], lbp=lookback).williams_r().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'ppo_{scale}'] = ta.momentum.PercentagePriceOscillator(close=df['Close'], window_slow=lookback, window_fast=lookback//2, window_sign = lookback//3).ppo().loc[tEvent]\n",
      "/var/folders/s5/v3s4h5vj3y946hk_7y92hmdr0000gn/T/ipykernel_73719/166524514.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'ppo_signal_{scale}'] = ta.momentum.PercentagePriceOscillator(close=df['Close'], window_slow=lookback, window_fast=lookback//2, window_sign = lookback//3).ppo_signal().loc[tEvent]\n"
     ]
    }
   ],
   "source": [
    "# Build Features\n",
    "X1 = pd.DataFrame(index = Y.index)\n",
    "X2 = pd.DataFrame(index = Y.index)\n",
    "\n",
    "df = df_ohlcv\n",
    "lookback = 100\n",
    "\n",
    "scale = 1\n",
    "X1 = add_featureSetA(X1, Y.index, df, scale, lookback)\n",
    "X2 = add_featureSetB(X2, Y.index, df, scale, lookback)\n",
    "\n",
    "scale = 4\n",
    "X1 = add_featureSetA(X1, Y.index, df, scale, lookback)\n",
    "X2 = add_featureSetB(X2, Y.index, df, scale, lookback)\n",
    "\n",
    "scale = 10\n",
    "X1 = add_featureSetA(X1, Y.index, df, scale, lookback)\n",
    "X2 = add_featureSetB(X2, Y.index, df, scale, lookback)\n",
    "\n",
    "scale = 40\n",
    "X1 = add_featureSetA(X1, Y.index, df, scale, lookback)\n",
    "X2 = add_featureSetB(X2, Y.index, df, scale, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1503, 172), (1503, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X1,X2], axis = 1)\n",
    "Y['cont'] = Y['ret'] # Return, Slope, Sharpe\n",
    "Y['bin'] = (Y['cont']>0).astype(int)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1453, 172) (1453, 3)\n"
     ]
    }
   ],
   "source": [
    "X_clean = X.replace([np.inf, -np.inf], np.nan)\n",
    "X_clean = X_clean.dropna()\n",
    "intersected_indices = X_clean.index.intersection(Y.index)\n",
    "Y_clean = Y.loc[intersected_indices]\n",
    "X_clean = X_clean.loc[intersected_indices]\n",
    "print(X_clean.shape, Y_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below for deployed model\n",
    "# trainStart, trainEnd = pd.to_datetime(\"2021-01-01\"), pd.to_datetime(\"2024-04-30\"); trainDays = (trainEnd - trainStart).days\n",
    "\n",
    "# This is for calculate returns for portfolio backtesting only\n",
    "trainStart, trainEnd = pd.to_datetime(\"2021-01-01\"), pd.to_datetime(\"2022-12-15\"); trainDays = (trainEnd - trainStart).days\n",
    "testStart, testEnd = pd.to_datetime(\"2023-01-01\"), pd.to_datetime(\"2024-04-30\"); testDays = (testEnd - testStart).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default precision: 0.5629937597386255\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_clean, Y_clean, test_size=0.15, shuffle=False)\n",
    "X_train, X_test, Y_train, Y_test = X_clean.loc[trainStart:trainEnd], X_clean.loc[testStart:testEnd], Y_clean.loc[trainStart:trainEnd], Y_clean.loc[testStart:testEnd]\n",
    "print('default precision:', Y_test[Y_test['cont']>0]['cont'].sum()/Y_test['cont'].abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF Simple\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth = 1, min_samples_leaf = 0.3, max_features=X.shape[1]//3,random_state=2, bootstrap = True, n_jobs=-1,)\n",
    "clf.fit(X_train, Y_train.bin, sample_weight=Y_train.cont.abs())\n",
    "y_proba_train = clf.predict_proba(X_train)[:,1]\n",
    "y_proba_test = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503, 172)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = set()\n",
    "for tree in clf.estimators_:\n",
    "    tree_features = tree.tree_.feature\n",
    "    used_features.update(tree_features[tree_features >= 0])\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    used_feature_names = [X_train.columns[i] for i in used_features]\n",
    "else:\n",
    "    used_feature_names = list(used_features)\n",
    "X_train_ = X_train.loc[:,used_feature_names]\n",
    "X_test_ = X_test.loc[:,used_feature_names]\n",
    "# RF Simple\n",
    "clf = RandomForestClassifier(n_estimators= 500, max_depth = 1, min_samples_leaf = 0.3, max_features='sqrt',random_state=1, bootstrap = True, n_jobs=-1,)\n",
    "clf.fit(X_train_, Y_train.bin, sample_weight=Y_train.cont.abs())\n",
    "y_proba_train = clf.predict_proba(X_train_)[:,1]\n",
    "y_proba_test = clf.predict_proba(X_test_)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 41)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_.shape\n",
    "# 36 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sharpe1_1', 'sharpe2_1', 'returns_1', 'std_1', 'vol_1', 'blgr_1',\n",
       "       'trend_1', 'trendblgr_1', 'willR_1', 'ar1_1', 'adf_1', 'macd_norm1_1',\n",
       "       'macd_norm2_1', 'sharpe1_4', 'sharpe2_4', 'returns_4', 'std_4', 'vol_4',\n",
       "       'blgr_4', 'trend_4', 'trendblgr_4', 'willR_4', 'ar1_4', 'adf_4',\n",
       "       'macd_norm1_4', 'macd_norm2_4', 'sharpe1_10', 'sharpe2_10',\n",
       "       'returns_10', 'std_10', 'vol_10', 'blgr_10', 'trend_10', 'trendblgr_10',\n",
       "       'willR_10', 'ar1_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3413639109.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    'trend_1', 'trendblgr_1', 'willR_1', 'ar1_1', 'adf_1', 'macd_norm1_1',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "'sharpe1_1', 'sharpe2_1', 'returns_1', 'std_1', 'vol_1', 'blgr_1',\n",
    "       'trend_1', 'trendblgr_1', 'willR_1', 'ar1_1', 'adf_1', 'macd_norm1_1',\n",
    "       'macd_norm2_1', \n",
    "\n",
    "'sharpe1_4', 'sharpe2_4', 'returns_4', 'std_4', 'vol_4',\n",
    "       'blgr_4', 'trend_4', 'trendblgr_4', 'willR_4', 'ar1_4', 'adf_4',\n",
    "       'macd_norm1_4', 'macd_norm2_4', \n",
    "\n",
    "'sharpe1_10', 'sharpe2_10',\n",
    "       'returns_10', 'std_10', 'vol_10', 'blgr_10', 'trend_10', 'trendblgr_10',\n",
    "       'willR_10', 'ar1_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "import pickle\n",
    "with open('xrp_model_v240524.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save return\n",
    "import pickle\n",
    "with open('Analysis/[S1] XRP_Reversion/events.pkl', 'wb') as f:\n",
    "    pickle.dump(events, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ret' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ret\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ret' is not defined"
     ]
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLTrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
